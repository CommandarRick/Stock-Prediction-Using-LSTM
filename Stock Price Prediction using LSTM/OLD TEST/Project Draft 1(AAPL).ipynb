{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries and functions used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function fetch_stock_data that makes use of web scraping to fetch historical stock data from yahoo finance for a specific company that the users chooses (for demonstration purposes we are currently using stock data for Apple(AAPL)).\n",
    "The data is then saved to an Excel file in the save_to_excel function which are both being called by the main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(stock_name):\n",
    "    end_date = int(datetime.now().timestamp())\n",
    "    start_date = int((datetime.now() - pd.DateOffset(days=1826)).timestamp())\n",
    "\n",
    "    url = f\"https://query1.finance.yahoo.com/v7/finance/download/{stock_name}?period1={start_date}&period2={end_date}&interval=1d&events=history\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    retries = 3\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                stock_data = pd.read_csv(io.StringIO(response.text))\n",
    "                return stock_data\n",
    "            else:\n",
    "                print(\"Failed to fetch data\")\n",
    "                print(f\"Status Code: {response.status_code}\")\n",
    "                return None\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            retries -= 1\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "\n",
    "    print(\"Maximum retries exceeded. Unable to fetch data.\")\n",
    "    return None\n",
    "\n",
    "def save_to_excel(stock_data, stock_name):\n",
    "    if stock_data is not None:\n",
    "        stock_data.to_excel(f\"Historical Data/{stock_name}.xlsx\", index=False)\n",
    "        print(f\"Stock data for {stock_name} saved successfully to the Excel file.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stock_name = input(\"Enter the stock ticker symbol: \")\n",
    "    data = fetch_stock_data(stock_name)\n",
    "    if data is not None:\n",
    "        save_to_excel(data, stock_name)\n",
    "    else:\n",
    "        print(\"Data retrieval failed or invalid ticker symbol provided.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a dataframe that reads the excel file and we can do some data analysis on the existing data to identify what parameters we want to train our LSTM model on.\n",
    "Firstly we analyze the Adjusted Close and Volume trends for the company by making various plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_excel(f\"Historical Data/{stock_name}.xlsx\")\n",
    "df.describe()\n",
    "df.info()\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)  # Set 'Date' column as the index\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "plt.plot(df['Adj Close'])\n",
    "plt.ylabel('Adj Close')\n",
    "plt.xlabel('Date')\n",
    "plt.title(f'Closing Price of {stock_name}')\n",
    "plt.show()\n",
    "df['Volume'].plot()\n",
    "plt.ylabel('Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.title(f\"Sales Volume for {stock_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify the daily return of the stock by using .pct_change() function which tells us how much of a daily difference here was in the adjusted close price  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_return = df['Adj Close'].pct_change()\n",
    "df_daily_return\n",
    "df_daily_return.plot( legend=True, linestyle='--', marker='o')\n",
    "plt.show()\n",
    "df_daily_return.hist(bins=50)\n",
    "plt.xlabel('Daily Return')\n",
    "plt.ylabel('Counts')\n",
    "plt.title(f'{stock_name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the moving average for the stock over 10,20 and 50 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "moving_avg = pd.read_excel(f\"Historical Data/{stock_name}.xlsx\")\n",
    "\n",
    "ma_day = [10, 20, 50]\n",
    "\n",
    "for ma in ma_day:\n",
    "    column_name = f\"MA for {ma} days\"\n",
    "    moving_avg[column_name] = moving_avg['Adj Close'].rolling(ma).mean()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "moving_avg[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes)\n",
    "axes.set_title(f'Stock Analysis for {stock_name}')\n",
    "\n",
    "# Adjust spacing between subplots here\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)  # You can modify these values as needed\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the expected return and the risk involved in investing the partiular stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_df = pd.read_excel(f\"Historical Data/{stock_name}.xlsx\")\n",
    "column_name = 'Adj Close'\n",
    "closing_df[column_name] = closing_df['Adj Close']\n",
    "closing_df['Adj Close'] = pd.to_numeric(closing_df['Adj Close'], errors='coerce')\n",
    "closing_df.dropna(subset=['Adj Close'], inplace=True)\n",
    "\n",
    "tech_return = closing_df['Adj Close'].pct_change()\n",
    "rets = tech_return.dropna()\n",
    "\n",
    "area = np.pi * 20\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(rets.mean(), rets.std(), s=area)\n",
    "plt.xlabel('Expected return')\n",
    "plt.ylabel('Risk')\n",
    "\n",
    "plt.annotate(rets.name, xy=(rets.mean(), rets.std()), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',\n",
    "             arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select the 'Adj Close' column to train our LSTM on, we would try and predict the future pries of the stock based on this data, we select this as our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pd.read_excel(f'Historical Data/{stock_name}.xlsx')['Adj Close']\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to reshape the data to fit in our lstm model, we first change the model shape to a numpy array of size(-1,1) and then use min ax scaller to transform the data to shape (0,1) which will then go into our LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = training_data.values.reshape(-1, 1)\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data=scaler.fit_transform(scaled_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a feature set array that stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set = []\n",
    "labels = []\n",
    "for i in range(60, len(scaled_data)):\n",
    "    features_set.append(scaled_data[i-60:i, 0])\n",
    "    labels.append(scaled_data[i, 0])\n",
    "features_set, labels = np.array(features_set), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new array containing scaled values from index 1543 to 2002\n",
    "df=pd.read_excel(f'Historical Data/{stock_name}.xlsx')\n",
    "data=df.filter(['Close'])\n",
    "dataset=data.values\n",
    "train_dataset_len=int(np.ceil(len(dataset)*.85))\n",
    "test_data = scaled_data[train_dataset_len - 60: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[train_dataset_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "\n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n",
    "    model.add(Dropout(0.65))\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.40))\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.40))\n",
    "    model.add(LSTM(units=32))\n",
    "    model.add(Dropout(0.40))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Assuming you have scaled_data available\n",
    "input_shape = (scaled_data.shape[1], 1)\n",
    "\n",
    "# Create the LSTM model\n",
    "lstm_model = create_lstm_model()\n",
    "\n",
    "validation_split = 0.2 \n",
    "split_index = int(len(features_set) * (1 - validation_split))\n",
    "train_features, val_features = features_set[:split_index], features_set[split_index:]\n",
    "train_labels, val_labels = labels[:split_index], labels[split_index:]\n",
    "\n",
    "mc = ModelCheckpoint(f'LSTM({stock_name}).hdf5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# Train the model\n",
    "history = lstm_model.fit(features_set, labels, epochs=700, batch_size=392,callbacks=[mc],validation_data=(val_features, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, confusion_matrix\n",
    "predictions = lstm_model.predict(features_set)\n",
    "mse = mean_squared_error(labels, predictions)\n",
    "mae = mean_absolute_error(labels, predictions)\n",
    "r2 = r2_score(labels, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model=load_model(f'LSTM({stock_name}).hdf5')\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "train = data[:train_dataset_len]\n",
    "valid = data[train_dataset_len:]\n",
    "valid_values=valid.values\n",
    "valid['Predictions'] = predictions\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_data contains the last 60 days of the available data\n",
    "x_test = []\n",
    "x_test.append(test_data[-60:])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "predictions = []\n",
    "\n",
    "for _ in range(15):\n",
    "        # Predict the next day\n",
    "        prediction = lstm_model.predict(x_test)\n",
    "        \n",
    "        # Append the prediction to the results\n",
    "        predictions.append(prediction[0, 0])\n",
    "\n",
    "        # Update x_test for the next prediction\n",
    "        x_test = np.roll(x_test, -1, axis=1)\n",
    "        x_test[0, -1, 0] = prediction\n",
    "\n",
    "    # Inverse transform the predictions to get actual stock prices\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "plt.plot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
